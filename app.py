import openai
from bottle import *
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from utils.aria_helper import generate_aria_tags_for_elements
from utils.gpt_service import get_system_message
from utils.image_recognition import extract_images_without_alt, generate_image_description
import json
import markdown
import time
import logging

# ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# APIã‚­ãƒ¼ã¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLã®è¨­å®š
load_dotenv()
api_key = os.getenv('OPENAI_API_KEY')
openai.api_key = api_key
openai.api_base = 'https://api.openai.com/v1'

BaseRequest.MEMFILE_MAX = 1024 * 1024

# --- CORSã¸ã®å¯¾å¿œ
@hook('after_request')
def enable_cors():
    response.headers['Access-Control-Allow-Origin'] = '*'
    response.headers['Access-Control-Allow-Methods'] = '*'
    response.headers['Access-Control-Allow-Headers'] = '*'

@route('/', method='OPTIONS')
def response_for_options(**kwargs):
    return {}

@post('/')
def index():
    try:
        data = request.json
        html_content = data['page']
        styles_content = data.get('styles', '')  # ã‚¹ã‚¿ã‚¤ãƒ«æƒ…å ±ã®å–å¾—
        scripts_content = data.get('scripts', '')  # ã‚¹ã‚¯ãƒªãƒ—ãƒˆæƒ…å ±ã®å–å¾—
        base_url = data.get('url')
        
        # å—ã‘å–ã£ãŸãƒ‡ãƒ¼ã‚¿ã®ãƒ­ã‚°å‡ºåŠ›
        logger.info("Received data:")
        logger.info(f"Base URL: {base_url}")
        logger.info(f"Styles content length: {len(styles_content)}")
        logger.info(f"First 500 chars of styles: {styles_content[:500]}")
        logger.info(f"Scripts content length: {len(scripts_content)}")
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å–å¾—
        system = get_system_message()
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ç½®æ›
        if isinstance(system['content'], str):
            system['content'] = system['content'].replace(
                '{HTML_CONTENT}', html_content[:1000]  # HTMLã®æœ€åˆã®1000æ–‡å­—
            ).replace(
                '{CSS_CONTENT}', styles_content[:1000]  # CSSã®æœ€åˆã®1000æ–‡å­—
            )
            logger.info("System message after replacement:")
            logger.info(f"First 500 chars: {system['content'][:500]}")
        
        aria_tags = generate_aria_tags_for_elements(html_content)
        description_md = gpt(html_content)
        description_html = markdown.markdown(description_md, extensions=['fenced_code'])
        
        # `alt` ã‚¿ã‚°ãŒãªã„ç”»åƒã‚’æŠ½å‡ºã—ã¦èª¬æ˜æ–‡ã‚’ç”Ÿæˆ
        image_sources = extract_images_without_alt(html_content)
        image_descriptions = []
        if not image_sources:
            alt_message = "ã™ã¹ã¦ã®ç”»åƒã«altã‚¿ã‚°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚"
        else:
            for src in image_sources:
                description = generate_image_description(src, api_key, base_url)
                image_descriptions.append({
                    'src': src,
                    'description': description['description'],
                    'alt': description['alt']
                })
            alt_message = None

        aria_message = "ã™ã¹ã¦ã®è¦ç´ ã«é©åˆ‡ãªARIAã‚¿ã‚°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚" if not aria_tags else None

        response.content_type = 'application/json'
        return json.dumps({
            'description': description_html,
            'aria_tags': aria_tags,
            'images_without_alt': image_descriptions,
            'alt_message': alt_message,
            'aria_message': aria_message
        }, ensure_ascii=False)
    except Exception as e:
        logger.error(f"Error processing request: {str(e)}", exc_info=True)
        response.status = 500
        return json.dumps({'error': 'Internal server error', 'details': str(e)})

@route('/favicon.ico')
def favicon():
    return ''

@route('/', method='GET')
def get_request():
    return "Server is running. Please use POST method."

def message(role, text):
    return {'role': role, 'content': text}
system = get_system_message()

def gpt(text):
    for attempt in range(3):
        try:
            response = openai.ChatCompletion.create(
                model='gpt-4o-mini',
                messages=[system] + [message('user', text)],
                response_format={"type": "json_object"}
            )
            generated_json = json.loads(response.choices[0].message['content'])
            logger.info("Generated JSON by GPT:")
            logger.info(json.dumps(generated_json, indent=2, ensure_ascii=False)[:500])
            
            # Convert JSON to markdown for existing markdown rendering
            markdown_description = convert_json_to_markdown(generated_json)
            return markdown_description
        except (openai.error.APIConnectionError, json.JSONDecodeError) as e:
            logger.error(f"Attempt {attempt + 1} failed: {str(e)}")
            if attempt < 2:
                time.sleep(2)
                continue
            else:
                raise e

def convert_json_to_markdown(json_data):
    markdown_output = "\n\n"
    filtered_criteria = [
        criterion for criterion in json_data.get('wcag_analysis', []) 
        if int(criterion['total_issues']) > 0
    ]

    for criterion in filtered_criteria:
        markdown_output += "\n\n"
        markdown_output += f"## ğŸ” é”æˆåŸºæº–: {criterion['criterion']} (ãƒ¬ãƒ™ãƒ«: {criterion['level']})\n\n"
        markdown_output += f"- **ã‚«ãƒ†ã‚´ãƒª:** {criterion['category']}\n"
        markdown_output += f"- **é‡è¦åº¦:** {criterion['importance']}\n"
        markdown_output += f"- **æ¤œå‡ºã•ã‚ŒãŸå•é¡Œæ•°:** {criterion['total_issues']}\n\n"

        markdown_output += "\n"

        for issue in criterion.get('issues', []):
            markdown_output += "### ğŸš¨ å…·ä½“çš„ãªå•é¡Œ\n\n"
            markdown_output += f"- **å•é¡Œç®‡æ‰€:** `{issue['location']}`\n"
            markdown_output += f"- **å•é¡Œç‚¹:** {issue['problem_description']}\n"
            markdown_output += f"- **å½±éŸ¿:** {issue['impact']}\n"
            markdown_output += f"- **æ·±åˆ»åº¦:** {issue['severity']}\n\n"

            markdown_output += "### ğŸ›  ä¿®æ­£ææ¡ˆ\n\n"
            markdown_output += f"**ææ¡ˆå†…å®¹:** {issue['recommendation']['description']}\n\n"
            markdown_output += f"**ä¿®æ­£ç†ç”±:** {issue['recommendation']['rationale']}\n\n"

            markdown_output += "#### ä¿®æ­£å‰:\n"
            markdown_output += f"```html\n{issue['recommendation']['code_before']}\n```\n\n"
            markdown_output += "#### ä¿®æ­£å¾Œ:\n"
            markdown_output += f"```html\n{issue['recommendation']['code_after']}\n```\n\n"

        if criterion.get('best_practices'):
            markdown_output += "### ğŸš€ é•·æœŸçš„ãªæ”¹å–„æˆ¦ç•¥\n\n"
            for practice in criterion['best_practices']:
                markdown_output += f"- {practice}\n"
            markdown_output += "\n---\n\n"

    summary = json_data.get('summary', {})
    if summary and int(summary.get('total_issues', 0)) > 0:
        markdown_output += "## ğŸ“Š ç·åˆã‚µãƒãƒªãƒ¼\n\n"
        markdown_output += f"- **å…¨ä½“ã®å•é¡Œæ•°:** {summary.get('total_issues', 'N/A')}\n\n"
        markdown_output += "\n---\n\n"
    return markdown_output


# run localhost
try:
    run(host='127.0.0.1', port=8000, reloader=True)
except KeyboardInterrupt:
    pass
